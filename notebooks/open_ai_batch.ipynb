{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48d2f9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28cf948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cdb83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "check what models the key has access to\n",
    "\n",
    "curl https://api.openai.com/v1/models \\\n",
    "  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0b3a9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_file = \"../csvs/baby_tests.csv\"   # contains: 'question 1'\\n'question 2'\\n...\n",
    "#output_file = \"../csvs/baby_tests.jsonl\"\n",
    "\n",
    "# all questions\n",
    "input_file = '../csvs/questions.csv'\n",
    "output_file = '../csvs/questions.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e53a54f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_general_prompt():\n",
    "    general_prompt = \"\"\"\n",
    "    \n",
    "    'Only use results from the genomic data commons in your response and provide frequencies \\\n",
    "     as a percentage in the result. Report the result in the following output JSON format, strictly using \\\n",
    "     the structure \"The final answer is: <frequency %>\", followed by top references to publications from which you \\\n",
    "     obtained your response:\n",
    "\n",
    "    {\n",
    "        result: The final answer is: <frequency %>\n",
    "        references: <list of references>\n",
    "    }\n",
    "\n",
    "    \"\"\"\n",
    "    return general_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fe0fdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_prompt = define_general_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c535b917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    \\n    \\'Only use results from the genomic data commons in your response and provide frequencies      as a percentage in the result. Report the result in the following output JSON format, strictly using      the structure \"The final answer is: <frequency %>\", followed by top references to publications from which you      obtained your response:\\n\\n    {\\n        result: The final answer is: <frequency %>\\n        references: <list of references>\\n    }\\n\\n    '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9574f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jsonl(input_file, output_file):\n",
    "    with open(input_file, \"r\") as infile, open(output_file, \"w\") as outfile:\n",
    "        next(infile)  # skip the header line\n",
    "        for i, line in enumerate(infile, 1):\n",
    "            question = line.strip().strip(\"'\\\"\")  # remove quotes and newline\n",
    "            jsonl = {\n",
    "                \"custom_id\": f\"request-{i}\",\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": \"gpt-4o-2024-08-06\",\n",
    "                    \"temperature\": 0,\n",
    "                    \"seed\": 2000,\n",
    "                    \"response_format\": {\"type\": \"json_object\"},\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": general_prompt},\n",
    "                        {\"role\": \"user\", \"content\": question}\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "            outfile.write(json.dumps(jsonl) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad369e08",
   "metadata": {},
   "source": [
    "### process results from batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab0b142",
   "metadata": {},
   "source": [
    "#### any errors from batch, reprocess them\n",
    "- look at error.jsonl and process the error queries separately\n",
    "- sometimes errors result due to the suffix \"-batch\" added to model name which doesn't exist\n",
    "- openai probably does this to get discounts in batch API\n",
    "- rerunning error queries fixes it and model name doesnt change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0975ed83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "questions = pd.read_csv('../csvs/questions.csv')\n",
    "error_questions = questions.iloc[[5, 6, 24, 80, 141, 169, 238, 246, 247, 265, 272, 287, 289, 309, 311, 407, 408, 416, 458, 485, 488]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96fdf716",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_questions.to_csv('../csvs/error_questions_gpt4.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3dd5418",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_jsonl(input_file='../csvs/error_questions_gpt4.csv', output_file='../csvs/error_questions_gpt4.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72adbe91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      " ['The final answer is: 2.5%', 'The final answer is: 2.5%', 'The final answer is: 2.5%']\n",
      "\n",
      "References:\n",
      " [['National Cancer Institute Genomic Data Commons Data Portal', 'The Cancer Genome Atlas Research Network publications on Uterine Carcinosarcoma'], [\"Publication 1: Smith et al., 2022, 'Genomic Characterization of Exceptional Responders in Cancer Therapy', Journal of Clinical Oncology.\", \"Publication 2: Johnson et al., 2023, 'PDGFRA Mutations in Exceptional Responders: Insights from the Genomic Data Commons', Cancer Research.\"], ['Genomic Data Commons Data Portal', 'CPTAC-3 Project Publications']]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "references_list = []\n",
    "\n",
    "with open(\"../csvs/batch_687c48ae86d88190910e8a35d5d4f6a9_output.jsonl\", \"r\") as file:\n",
    "    for line in file:\n",
    "        record = json.loads(line)\n",
    "\n",
    "        try:\n",
    "            # Step 1: Get the assistant message content (which is a JSON string)\n",
    "            content_str = record[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "            # Step 2: Parse that content string as JSON\n",
    "            content_json = json.loads(content_str)\n",
    "\n",
    "            # Step 3: Extract result and references\n",
    "            result = content_json.get(\"result\")\n",
    "            references = content_json.get(\"references\", [])\n",
    "\n",
    "            results.append(result)\n",
    "            references_list.append(references)\n",
    "\n",
    "        except (KeyError, json.JSONDecodeError) as e:\n",
    "            print(\"Error parsing line:\", e)\n",
    "            results.append(None)\n",
    "            references_list.append([])\n",
    "\n",
    "# Output examples\n",
    "print(\"Results:\\n\", results)\n",
    "print(\"\\nReferences:\\n\", references_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f07b0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "baby_test_questions = pd.read_csv(\n",
    "    '../csvs/baby_tests.csv'\n",
    ")\n",
    "baby_test_questions['gpt-4o-2024-08-06_base_output'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "707e7870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>gpt-4o-2024-08-06_base_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the incidence of simple somatic mutati...</td>\n",
       "      <td>The final answer is: 2.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the incidence of simple somatic mutati...</td>\n",
       "      <td>The final answer is: 2.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the incidence of simple somatic mutati...</td>\n",
       "      <td>The final answer is: 2.5%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions  \\\n",
       "0  What is the incidence of simple somatic mutati...   \n",
       "1  What is the incidence of simple somatic mutati...   \n",
       "2  What is the incidence of simple somatic mutati...   \n",
       "\n",
       "  gpt-4o-2024-08-06_base_output  \n",
       "0     The final answer is: 2.5%  \n",
       "1     The final answer is: 2.5%  \n",
       "2     The final answer is: 2.5%  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baby_test_questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Poetry venv-3.10.13",
   "language": "python",
   "name": "venv-3.10.13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
