{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# MCP tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU-0 in devices, GPU-1 on the scheduler\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # note the GPU index as a string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# this notebook is in notebooks â€” go up one level\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gdc_pipeline import execute_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### wrap gdc_rag pipeline in a tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init a dummy list\n",
    "sys.argv = ['prog', '--input-file', 'dummy.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gdc_pipeline import setup_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = setup_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.hf_token_path='.token'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapped_execute_pipeline(input_file: str):\n",
    "    print(f'Tool received: {input_file}')\n",
    "    return execute_pipeline(\n",
    "        input_file=input_file,\n",
    "        intent_model_path=args.intent_model_path,\n",
    "        path_to_gdc_genes_mutations=args.path_to_gdc_genes_mutations_file,\n",
    "        hf_token_path=args.hf_token_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_tool = Tool(\n",
    "    name=\"run_pipeline_on_file\",\n",
    "    func=wrapped_execute_pipeline,\n",
    "    description=\"Run the pipeline on a CSV file. Input is a file 'questions.csv'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### define agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.language_models.fake import FakeListLLM\n",
    "\n",
    "agent_llm = FakeListLLM(responses=[\n",
    "    \"\"\"Thought: I should use the tool\n",
    "    Action: run_pipeline_on_file\n",
    "    Action Input: questions.csv\"\"\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### react style prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://api.python.langchain.com/en/latest/agents/langchain.agents.react.agent.create_react_agent.html\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"You are an assistant with access to a tool named `run_pipeline_on_file`. Your job is to run this tool on a file questions.csv.\n",
    "\n",
    "{tools}\n",
    "\n",
    "Thought: I should call the tool {tool_names}\n",
    "Action: run_pipeline_on_file\n",
    "Action Input: questions.csv\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    template\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### create agent and executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "\n",
    "agent = create_react_agent(\n",
    "    llm=agent_llm,\n",
    "    tools=[mcp_tool],\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent,\n",
    "    tools=[mcp_tool],\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    max_iterations=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Run agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke(\n",
    "    {'input': \"Can you retrieve answers for the file questions.csv\"}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
